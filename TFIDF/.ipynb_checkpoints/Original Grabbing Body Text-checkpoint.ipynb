{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n",
    "import sys\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv\n",
    "df = pd.read_csv(\"gnews_refined_sept2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>Search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New Course from ChildCare Education Institute ...</td>\n",
       "      <td>2020-06-11 22:26:00 UTC</td>\n",
       "      <td>YAHOO!</td>\n",
       "      <td>https://finance.yahoo.com/news/course-childcar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1 in 7 with COVID-19 symptoms avoiding care—ra...</td>\n",
       "      <td>2020-04-28 12:25:00 UTC</td>\n",
       "      <td>Radiology Business</td>\n",
       "      <td>https://www.radiologybusiness.com/topics/care-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>New box shields protect healthcare staff perfo...</td>\n",
       "      <td>2020-08-06 22:41:00 UTC</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>https://www.straitstimes.com/singapore/new-box...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Telemonitoring solutions for Covid-19 patients...</td>\n",
       "      <td>2020-08-01 22:00:00 UTC</td>\n",
       "      <td>The Straits Times</td>\n",
       "      <td>https://www.straitstimes.com/singapore/telemon...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>‘This is not working.’ Parents juggling jobs a...</td>\n",
       "      <td>2020-07-23 13:15:00 UTC</td>\n",
       "      <td>PBS</td>\n",
       "      <td>https://www.pbs.org/newshour/health/this-is-no...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  New Course from ChildCare Education Institute ...   \n",
       "1           1  1 in 7 with COVID-19 symptoms avoiding care—ra...   \n",
       "2           2  New box shields protect healthcare staff perfo...   \n",
       "3           3  Telemonitoring solutions for Covid-19 patients...   \n",
       "4           4  ‘This is not working.’ Parents juggling jobs a...   \n",
       "\n",
       "                  Datetime              Source  \\\n",
       "0  2020-06-11 22:26:00 UTC              YAHOO!   \n",
       "1  2020-04-28 12:25:00 UTC  Radiology Business   \n",
       "2  2020-08-06 22:41:00 UTC   The Straits Times   \n",
       "3  2020-08-01 22:00:00 UTC   The Straits Times   \n",
       "4  2020-07-23 13:15:00 UTC                 PBS   \n",
       "\n",
       "                                                 URL  Search  \n",
       "0  https://finance.yahoo.com/news/course-childcar...     NaN  \n",
       "1  https://www.radiologybusiness.com/topics/care-...     NaN  \n",
       "2  https://www.straitstimes.com/singapore/new-box...     NaN  \n",
       "3  https://www.straitstimes.com/singapore/telemon...     3.0  \n",
       "4  https://www.pbs.org/newshour/health/this-is-no...     3.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\":\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in 55.113614200000015 seconds\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "final = {}\n",
    "\n",
    "def download_text(url):\n",
    "    try:\n",
    "        global info\n",
    "        info = {}\n",
    "        r = requests.get(url, headers = headers)\n",
    "        time.sleep(10)\n",
    "        html_doc= r.text\n",
    "        soup = BeautifulSoup(html_doc, 'lxml')\n",
    "        #print(soup.prettify())\n",
    "        if soup.find_all('p'):\n",
    "            y =\"\"\n",
    "            for x in soup.find_all('p'):\n",
    "                y += x.get_text()\n",
    "            info[url] = y      #changed soup.title.text with url\n",
    "        elif soup.find_all('section'):\n",
    "            y = \"\"\n",
    "            for x in soup.find_all('section'): #section class = 'articlebody'\n",
    "                y += x.get_text()\n",
    "            info[url] = y     #changed soup.title.text with url\n",
    "    except:\n",
    "        e = sys.exc_info()[0]\n",
    "        print(e)\n",
    "        print(url)\n",
    "    \n",
    "    final.update(info)\n",
    "  \n",
    "  \n",
    "for chunk in pd.read_csv(\"gnews_refined_sept2.csv\",chunksize = 50):   #INPUT CSV FILE HERE \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        executor.map(download_text, chunk.iloc[:,4]) #change 4 to the column number of URL\n",
    "        \n",
    "    \n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(f'Finished in {t2-t1} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the original dataset is  157\n",
      "\n",
      "\n",
      "The number of articles we succesfully grabbed body text from is  156\n"
     ]
    }
   ],
   "source": [
    "#confirmation that we have all/most the articles\n",
    "i = pd.read_csv('gnews_refined_sept2.csv')\n",
    "print('The length of the original dataset is' ,len(i))\n",
    "print(\"\\n\")\n",
    "print('The number of articles we succesfully grabbed body text from is',len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to dataframe\n",
    "body_text = pd.DataFrame(list(final.items()),columns = ['url','body_text']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding body text to original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(df)):\n",
    "    for y in range(len(body_text)):\n",
    "        if df.iloc[x,4] == body_text.iloc[y,0]:\n",
    "            df.loc[x,'body_text' ] = body_text.loc[y,'body_text']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Title\n",
      "Datetime\n",
      "Source\n",
      "URL\n",
      "Search\n",
      "body_text\n"
     ]
    }
   ],
   "source": [
    "#look for columns\n",
    "for x in df.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#look for na in rows\n",
    "for x in range(len(df.columns)):\n",
    "    print(df.iloc[:,x].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to df\n",
    "df.to_csv('Articles_textv5.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
