{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy.linalg as LA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv(\"covid_articles_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\ngofundmeA college senior from Versailles, Wo...\n",
       "1    Baltimore-based company has developed CDC-alig...\n",
       "2    The need for innovative solutions to address s...\n",
       "3    An award-winning team of journalists, designer...\n",
       "4                                                  NaN\n",
       "Name: body_text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"body_text\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "data = data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for null\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\ngofundmeA college senior from Versailles, Wo...\n",
       "1    Baltimore-based company has developed CDC-alig...\n",
       "2    The need for innovative solutions to address s...\n",
       "3    An award-winning team of journalists, designer...\n",
       "5    Want to discuss? Please read our Commenting Po...\n",
       "Name: body_text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"body_text\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"combined_body_text\"] = data.filter(regex=(\"body_text\")).apply(lambda x: ''.join(str(x.values)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "data[\"combined_body_text\"] = [REPLACE_BY_SPACE_RE.sub('',row) for row in data[\"combined_body_text\"]]\n",
    "data[\"combined_body_text\"] = [BAD_SYMBOLS_RE.sub('',row) for row in data[\"combined_body_text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ngofundme college senior from ersailles oodfor...\n",
       "1    altimorebased company has developed aligned so...\n",
       "2    he need for innovative solutions to address sh...\n",
       "3    n awardwinning team of journalists designers a...\n",
       "5    ant to discuss lease read our ommenting olicy ...\n",
       "Name: combined_body_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"combined_body_text\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ngofundme college senior from ersailles oodfor...\n",
      "1    altimorebased company has developed aligned so...\n",
      "2    he need for innovative solutions to address sh...\n",
      "3    n awardwinning team of journalists designers a...\n",
      "5    ant to discuss lease read our ommenting olicy ...\n",
      "Name: bag_of_words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing\n",
    "data[\"bag_of_words\"] = data[\"combined_body_text\"]\n",
    "print(data[\"bag_of_words\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip punctuation\n",
    "# This uses str.translate to map all punctuation to the empty string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "data[\"bag_of_words\"] = [row.translate(table) for row in data[\"bag_of_words\"]]\n",
    "#print(data[\"bag_of_words\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all numbers in the article to the word 'num' using regular expressions\n",
    "data[\"bag_of_words\"] = [re.sub(r'\\d+', 'num', row) for row in data[\"bag_of_words\"]]\n",
    "#print(data[\"bag_of_words\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [ngofundme, college, senior, ersailles, oodfor...\n",
      "1    [altimorebased, company, developed, aligned, s...\n",
      "2    [need, innovative, solutions, address, shortag...\n",
      "3    [n, awardwinning, team, journalists, designers...\n",
      "5    [ant, discuss, lease, read, ommenting, olicy, ...\n",
      "Name: bag_of_words, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "data[\"bag_of_words\"] = [[word.lower() for word in row.split() if word.lower() not in stopwords] for row in data[\"bag_of_words\"]]\n",
    "print(data[\"bag_of_words\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming (A better option would be to lemmatize, but it takes forever)\n",
    "stemmer = PorterStemmer()\n",
    "data[\"bag_of_words\"] = [\" \".join([stemmer.stem(word) for word in row]) for row in data[\"bag_of_words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing dataset\n",
    "vectorizer = TfidfVectorizer(tokenizer = word_tokenize, analyzer = \"word\", ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(data[\"bag_of_words\"].values)\n",
    "#print(data[\"X\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 65531)\t0.037770432631338356\n",
      "  (0, 45730)\t0.037770432631338356\n",
      "  (0, 2015)\t0.037770432631338356\n",
      "  (0, 69895)\t0.037770432631338356\n",
      "  (0, 14370)\t0.037770432631338356\n",
      "  (0, 22909)\t0.037770432631338356\n",
      "  (0, 18850)\t0.037770432631338356\n",
      "  (0, 7369)\t0.037770432631338356\n",
      "  (0, 4348)\t0.037770432631338356\n",
      "  (0, 30773)\t0.037770432631338356\n",
      "  (0, 26593)\t0.037770432631338356\n",
      "  (0, 56485)\t0.037770432631338356\n",
      "  (0, 10836)\t0.037770432631338356\n",
      "  (0, 9101)\t0.037770432631338356\n",
      "  (0, 4717)\t0.037770432631338356\n",
      "  (0, 75953)\t0.037770432631338356\n",
      "  (0, 73851)\t0.037770432631338356\n",
      "  (0, 85402)\t0.03493147871573923\n",
      "  (0, 45532)\t0.037770432631338356\n",
      "  (0, 44613)\t0.037770432631338356\n",
      "  (0, 68464)\t0.037770432631338356\n",
      "  (0, 70021)\t0.037770432631338356\n",
      "  (0, 75020)\t0.037770432631338356\n",
      "  (0, 17976)\t0.037770432631338356\n",
      "  (0, 23050)\t0.037770432631338356\n",
      "  :\t:\n",
      "  (127, 11410)\t0.030031047964142746\n",
      "  (127, 55932)\t0.028630336683598826\n",
      "  (127, 51088)\t0.017848504829776263\n",
      "  (127, 66339)\t0.019368275853841287\n",
      "  (127, 49490)\t0.02566698599094822\n",
      "  (127, 20535)\t0.01873107839934572\n",
      "  (127, 69239)\t0.08785772852526581\n",
      "  (127, 9906)\t0.015716497445712733\n",
      "  (127, 30609)\t0.02041161183837998\n",
      "  (127, 9144)\t0.017848504829776263\n",
      "  (127, 27217)\t0.022227368387313078\n",
      "  (127, 54696)\t0.021176373548029936\n",
      "  (127, 64426)\t0.027798993375011745\n",
      "  (127, 44509)\t0.049512704856564074\n",
      "  (127, 47664)\t0.04002103570896186\n",
      "  (127, 73064)\t0.026326172916098494\n",
      "  (127, 30952)\t0.022227368387313078\n",
      "  (127, 58119)\t0.014068653560345793\n",
      "  (127, 32027)\t0.02930760185223122\n",
      "  (127, 49894)\t0.04926978468166599\n",
      "  (127, 33511)\t0.019044366163966413\n",
      "  (127, 41959)\t0.019875709472553495\n",
      "  (127, 83990)\t0.017848504829776263\n",
      "  (127, 48821)\t0.022452188660781705\n",
      "  (127, 62846)\t0.020786343035219677\n",
      "[0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#Set random seed\n",
    "Y = data[\"Relevant\"]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(X_train)\n",
    "print(Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', probability=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train classifier\n",
    "# DOESNT WORK RN COZ WE ONLY GOT 1 CLASS: RELEVANT SHOULD BE 1 AND 0\n",
    "clf = SVC(probability=True, kernel='linear')\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC yields 0.8897058823529411\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict_proba(X_test)\n",
    "print('ROC-AUC yields ' + str(roc_auc_score(Y_test, predictions[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7895384615384614\n",
      "{'degree': 2, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters_svm = {\"kernel\": [\"rbf\", \"poly\", \"linear\"], \"gamma\": [\"scale\", \"auto\"], \"degree\": [2, 3]}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(clf, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(X_train, Y_train)\n",
    "print(gs_clf_svm.best_score_)\n",
    "print(gs_clf_svm.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
